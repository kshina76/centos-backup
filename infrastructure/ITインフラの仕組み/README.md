# ITインフラの仕組み 書籍メモ

## 2. サーバを開けてみよう
### CPUの内部構造
- P44

## 3. 3階層型システムを見てみよう
### 3-1. OSカーネル
1. システムコールインタフェース
  - アプリケーションはOSを通じて処理を行いたい時は、システムコールインタフェースを通じて命令する
  - 例えば、ネットワーク接続をしたい場合は4番のネットワークスタックにシステムコールインタフェースを介して呼び出す
  - ファイルシステム管理、デバイスドライバーも同じく
6. デバイスドライバー
  - ディスクやNICなどのインタフェースを提供する
  - NICやディスクは色々なベンダーが開発していて、それらを意識するのは大変だからインタフェースによって隠蔽している
  - DBへの接続にもデバイスドライバーが使われる
- P52

## 4. インフラを支える理論の基本
### 直列と並列
- データベースは1コネクションあたり1プロセスを起動する
- DBWRプロセスの(データベースライタープロセス)数を増やして並列でI/Oを発行することも可能
- 非同期I/Oを使ってOS側で書き込みを並列化する仕組みもある
  - insert,update,deleteの時のような書き込む時にデータベースはカーネルレベルで非同期I/Oを実現していので、ソフトウェア側の書き込む時には非同期I/Oで処理してしまって問題ない
- 非同期通信のAjaxの例
  - Googleの検索欄に文字を入力すると、候補が出てくる。これもAJAX
    - 入力中の文字をAjaxによってgoogleのサーバに送信されて、送り返されて表示している
- データベースの書き込みで、非同期でどんどんI/Oを発行してもストレージの速度を超えることはないから大丈夫
- C10K問題とノンブロッキングI/O

### キューとは
- ディスクI/Oについて解説している
- p99~101

### 探索アルゴリズム
- sqlのインデックスについて解説している
- 124~132

## 5. インフラを支える理論の応用
### キャッシュ
- CPUの一次キャッシュ、二次キャッシュ
- ストレージのキャッシュ
- OSのページキャッシュ
- データベースのバッファキャッシュ
- ブラウザキャッシュ(P136の図)
  - Webブラウザにアクセス先のページをキャッシュするもの
  - Webサーバに対するアクセスを減らし、ブラウザでの表示を高速化できる
  - Webサーバの負荷を減らす
- CDN(P136の図)
  - Webサーバとクライアントの間にキャッシュサーバを配置
  - Webサーバの負荷を減らす
- キャッシュが向いているシステム
  - 参照されることが多いデータ
  - キャッシュ上のデータが失われても問題ないシステム
- キャッシュが不向きなシステム
  - データの更新が頻繁にあるシステム
  - 大量のデータにアクセスするシステム
### レプリケーション、マスターワーカー
- P162~170

## 6. ネットワーク
### 階層構造
- OSI参照モデルとか
- 階層構造はネットワークだけのものではない
  - レイヤードアーキテクチャ
  - サーバの中身も階層構造(P188)
### プロトコル
- プロトコルはTCP/IPだけのものではない
  - マウスをPCと繋ぐときのUSBにもプロトコルが存在する
  - ストレージからデータを取り出すときにもプロトコルが決まっていて、SCSIプロトコルなどがある
  - マルチコアのCPUのコア同士が通信する際にもプロトコルが存在する
### TCP/IP4階層モデルとシステムの対応関係(これが知りたかった！！)
- アプリケーション層: プロセス
- TCP, IP: カーネル
- Ethernet, 物理層: ハードウェア
- P195の図

### P184~全てをまとめる

### アプリケーション層
- カーネルにIPアドレスとポート番号を渡すと接続先に繋がるソケットを開いてくれる
- アプリケーション層の仕事はプロトコルに沿ったデータを開いたソケットに書き込むだけ
- TCP/IPでの通信はソケットの先のカーネルが担当してくれる
  - データをパケットに包んだり
- 最終的にデータが送信されるのはNICなので、ソケットに書き込んだデータがトランスポート層から一気に相手のトランスポート層にデータが届けられることはない
  - しかし、下の層の動きは隠蔽されているので、プロセスから見るとソケットからソケットに直接データが届けられているように見える(この経路を仮想経路という)
### トランスポート層
- TCPの役割は「サーバからデータを送信する時」と「サーバが受信した後のアプリケーションに渡す時」
- 相手のサーバに送り届ける部分は下の層のIP層が担当する
- IP層だけでも通信することはできるが、データの信頼性などを高めるにはTCPが必要。さらにパケットに分割しているデータがバラバラに届いてしまったりもする
- TCPの機能
  - ポート番号によるデータ転送
  - コネクションの生成
  - データの保証と再送制御
  - フロー制御と輻輳制御(ネットワーク上でアクセスが一つに集中することを防ぐ)
- MSSというサイズでデータをセグメントに分割していく
  - MSSは1460byteであることが多い
  - 2000byteのデータがアプリケーション層から書き込まれた場合、1460byteと540byteに分けて、それぞれにセグメント番号などの様々な情報を付けてIP層に送信される
- 3way-handshakeももちろん最終的にはNICから出て行われる。トランスポート層から見ると接続先のトランスポート層と直接やりとりしているように見える
  - 3way-handshakeによって仮想経路(コネクション)が生成される
- TCPの再送制御
  - 通常は受信側がACKで次に欲しいシーケンス番号を伝えて、次のパケットを送信してもらう
  - 受信側から一定時間内にACKが届かなかったら、タイムアウトとして再送する
### ネットワーク層
- パケットが循環してしまって、行き場を失った場合はルータが破棄する。その際の指標となるのがTTL(Time to Live)で、TTLが64の場合はルータを経由するたびに63,62,...と減らして0になったら破棄する
- 217, 223の図
### データリンク層
- Ethernetが使われることが多い
- 役割としては、「同一ネットワーク内のネットワーク機器まで、渡されたデータを届ける」
- IP層のルーティングテーブルによって次に送信するべきIPアドレスが決定される
  - 送信されるべきIPアドレスはデフォルトゲートウェイだったりする
- データリンク層はIP層によって決まったIPアドレスに対応するMACアドレスをARPテーブルを使って取得する
  - IPアドレスに該当するMACアドレスがなかった場合は、ブロードキャストアドレスを使って同一ネットワーク内のネットワーク機器全てに送信して、応答が返ってきた機器にデータを送信する
- P226の画像
- IP層とリンク層での見え方の違い
  - P234の画像
### 最終宛先での受信処理
- P235

## 7.止めないためのインフラの仕組み
### 冗長化の仕組み
- 負荷を均等にするための、負荷分散
- ダウンしたサーバがないかを定期的に監視する、死活監視
- ダウンした場合の補欠のサーバを決定するための、稼働担当の決定
- 補欠がいる場合に安全に要員交代ができる仕組みの、フェイルオーバー
  - アクティブ-スタンバイ構成の場合に問題が発生したら、スタンバイからアクティブに切り替わることをフェールオーバーという
### NICの冗長化
- NICの冗長化としては、MII監視とやARP監視という方法がある
### ストレージの冗長化
- 248-255
### Webサーバの冗長化(プロセスとスレッドの冗長化)
- apacheはリクエストの受付にプロセスかスレッドを選択できる
- プロセスの場合はPIDが全て違うが、スレッドの場合はPIDが同じ
- システムリソースに余裕があれば、起動するプロセス/デーモンの数の最小値と最大値は同じにする
  - 同一の値にすることで、プロセスやスレッドの起動/停止のオーバーヘッドを削減できる
### Webサーバの冗長化(Webサーバ自身の冗長化)
- DNSラウンドロビン
  - 一つのホスト名に対して複数のIPアドレスをDNSに登録することで、DNSが順番に異なるIPアドレスを返す方法
  - DNSはWebサーバの死活監視をしてるわけではないので、可用性を重視する場合は不向き
  - DNSはセッションの状態を把握しないので、次にアクセスする際に同じサーバにアクセスしなければいけない場合は不向き
    - HTTPをセッションステートフルで行う場合に不向きということ
- ロードバランサー
  - ロードバランシングしつつセッションステートフルを実現する機能をパーシステンス機能という
  - パーシステンス機能
    - ソースIPアドレス: IPアドレスを元に割り振る方法(IPアドレスの末尾が奇数ならWebサーバ1に割り振るとか)
    - Cookie: HTTPヘッダー内にどのWebサーバにアクセスしたかを記録しておく
    - URL: URL内にクエリ文字列で情報を埋め込む(http://example.com?sessid=webserver1 のように)
  - ロードバランサーのアルゴリズム
    - ラウンドロビン
    - リーストコネクション
    - レスポンスタイム
### APサーバの冗長化(APサーバ自身の冗長化)
- Webサーバの冗長化と同じ
  - リクエストの分散、セッション情報の保持もWebサーバの冗長化と同じ
- ロードバランサーでWebサーバからのリクエストを負荷分散するための冗長化
### APサーバの冗長化(セッション情報の冗長化)
### APサーバの冗長化(DBへのコネクションの冗長化)
### DBサーバの冗長化(アクティブ-スタンバイ)
### DBサーバの冗長化(アクティブ-アクティブ)
### ネットワーク機器の冗長化(L2スイッチの冗長化)
### ネットワーク機器の冗長化(L3スイッチの冗長化)
### サイトの冗長化(今までの冗長化を全て組み合わせた際の図)
- P290の図
- サイト間の冗長化は、グローバルサーバロードバランシング(GSLB)というもので行う
  - 例えば、東京と大阪でロードバランシングすると、東京で障害があったときに大阪が担うといったことができる
  - AWSでいうリージョン間やAZ間の冗長化がこれにあたる

## 性能を出すためのインフラの仕組み
### どこがボトルネックになってレスポンスタイムが遅くなっているか
- レスポンスタイムはリクエストを投げてからレスポンスが返ってくるまでの時間
- P312
### 3階層の図と照らし合わせながら実際にボトルネックを解消する実践編
- P319から最後まで
