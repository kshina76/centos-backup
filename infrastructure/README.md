# システムのパフォーマンスチューニング
## コンピュータの事前知識で必要なこと
- HDDやSSDにもマイコン(CPU)が内蔵されていて、そのマイコンがI/Oの処理を行うので、サーバのCPUがI/Oの処理を行っているわけではない(windowsのディスク使用率がそのマイコンの負荷)
  - プロセスがI/O待ちになって、CPU使用率が上がらないのは、HDDヤSSD内臓のマイコン(CPU)が処理をしているのを待っていることが原因
  - https://qiita.com/gpsnmeajp/items/eedb3ed788add25df11c

## 大まかな手順
### 1. ITインフラの仕組みのCheatSheet.mdとREADME.mdの図を参照にしながら計測することを心がけるとわかりやすい
- 計測することで自分が担当しているインフラのどこでボトルネックが発生しているかを突き止めて、そこをドリルダウンしていく方法が一番有効
- Webでの通信の流れを一目で把握するのに以下を参照
  - https://github.com/kshina76/centos-backup/blob/master/infrastructure/ITインフラの仕組み/CheatSheet.md
### 2. ゴール設定
- 一つのボトルネックを潰すと、新しくボトルネックが発生するということがよく起きる
  - APサーバを冗長化して捌けるリクエストの数が増えると、裏のDBサーバへのリクエスト数が増加するので、DBサーバが次のボトルネックになったりする
- ボトルネックを全て潰すといったゴールは終わりがないので、明確なゴールを設定する必要がある
- ゴール設定の例
  - 特定のレスポンスを何%改善する
  - アプリケーションを含めて、システム全体でのレスポンスタイムを何%改善する
### 3. ボトルネックを突き止める
- レスポンスからリクエストまでの経路でどこに時間がかかっているかを突き止めるのに使う図(https://github.com/kshina76/centos-backup/blob/master/infrastructure/ITインフラの仕組み/README.md のP312)
  - 区間がわかったらさらに細かく内部の計測を始めるといった感じで、「全体の計測->区間の計測->さらに細かく計測->...->ボトルネック箇所発見」という感じで進める
- サーバ側の問題だと思ったら、クライアントのPCのブラウザのレンダリングが遅いだけだったという場合もありえる
- ボトルネック一覧
  - CPUボトルネック
  - メモリボトルネック
  - ディスクI/Oボトルネック
  - ネットワークI/Oボトルネック
  - アプリケーションボトルネック
### 4. ボトルネックの箇所を特定したら、なぜそのボトルネックが発生しているのかの原因を考える
- リソースが足りていないのかとか、コネクションプールの容量が小さすぎて都度コネクションを張ってしまっているのかとか、いろいろな原因が考えられる
- ITインフラの仕組みのP319から最後までを見ると答えがあるかも
### 5. ボトルネックの原因がわかったら、解決策を考える、調べる
- レスポンスタイムとスループットを改善しないといけない
  - 「サーバの冗長化、CPUコア数の増加」によってスケールアウトをしてスループットだけを改善しても、一つのプロセスの処理速度が上がるわけではないので、一つのプロセスのレスポンスタイムは改善しない可能性もあるから
- まずはインフラレベルの問題を解決すればボトルネックを解決できるのか、アプリケーションの実装の問題を解決すればボトルネックを解決できるのかを考えないといけない
- Webサーバの負荷が一箇所に集中してしまっているなら、ロードバランサーのアルゴリズムの変更を考えるとか
- ユーザのアクセス数を減らす流量制御という方法をとるとか
- 冗長化を網羅した記事は(https://github.com/kshina76/centos-backup/blob/master/infrastructure/ITインフラの仕組み/README.md)
- キャッシングを網羅した記事は()

## さらに細かい手順(1,3の手順)

## さらに細かい手順(4~5の手順)
- このページで網羅していないものは以下を参照
  - https://github.com/kshina76/centos-backup/tree/master/infrastructure/ISUCON
- 前提条件として、大まかな手順の1~3でCPUでボトルネックが発生していることを見つけおく
### CPUボトルネック
- **待ち行列でのボトルネック問題**
  - 発生原因の特定
    - 「CPU使用率が高い」かつ「OS上で稼働しているプロセス数が多い」場合は、待ち行列でのボトルネックが発生する可能性が高い
    - vmstatなどで一番左の「Run Queue」という値が増加していたら、待ちプロセスが多く、ボトルネックになっている可能性が高い
  - 解決策
    - スループットの改善
      - CPUコア数の増加
      - サーバを追加して処理を分散させる(冗長化する)
- **レスポンスでのボトルネック問題**
  - 発生原因
    - プロセスの処理が重くて、単一のCPUだと処理に追いつかなくなってしまう
  - 発生原因の特定
    - 上記と同じ
  - 解決策
    - レスポンスタイムの改善
      - CPUのクロック数を上げる(クロック数が二倍になれば、レスポンスタイムは半分になる)
      - 一つのプロセスを複数のCPUで同時に処理させる
        - 並列化、マルチプロセス化、マルチスレッド化をして複数CPUを利用させる
- **CPU使用率が上がらない問題**
  - 発生原因
    - データベースなどはI/Oの数が多いので、プロセスがI/O待ちになってしまい、CPUに処理する出番が回ってこない
  - 解決策
    - 処理の多重化
      - プロセス、スレッドを増やすことでI/Oの数が増える -> CPUが捌く量が増える -> CPU使用率が上がる
    - I/Oの非同期化
      - プロセスがI/Oを待たないで次の処理に向かうことができる -> CPUに出番が回ってくる -> CPU使用率が上がる
    - データベースサーバをスケールアップ/スケールアウトさせてもいい気がする
      - データベースの処理速度が向上 -> I/O処理がすぐ終わる -> プロセスがCPUを使う -> CPU使用率が上がる
### メモリボトルネックの解消
- **領域不足によるボトルネック**
  - 発生原因
    - スワッピング、ページングが発生することでI/O待ちが発生する
  - 解決策
    - プロセスごとのメモリ領域のサイジングにも気を配る
- **同じデータに対するボトルネック**
  - P333~335
### ディスクI/Oボトルネックの解消
- **外部ストレージ**
  - P335~337
  - SSDとかメモリにキャッシュするようにする
- **シーケンシャルI/OとランダムI/O**
  - P338~340
  - SSDとかメモリにキャッシュするようにする
### ネットワークI/Oボトルネックの解消
- **通信プロセスのボトルネック**
  - P342~343
  - 発生原因
    - DBサーバからネットワークで送信できるデータの帯域幅を増やしても、APサーバ上のプロセスがシングルで走っている場合に、結局小さい帯域幅でデータを送ることになってしまう
  - 解決策
    - データを圧縮する
      - データを圧縮すること自体にもCPUを使うので、バランスよく行う
    - APサーバ上のプロセス数を増やして並列処理をさせると、ネットワークの帯域幅を使い切ることができる
      - CPUコアの個数にプロセス数を増やす
- **ネットワーク経路のボトルネック**
  - 発生原因
    - 通信する際に、全ての処理が特定のネットワーク機器(ルータなど)を通過するといったときに、ネットワーク機器が処理限界を迎えてボトルネックになってしまう
  - 解決策
    - 特定の処理をルータを介さないでも通信できるようにする
      - 「クライアント -> ルータ -> AP -> ルータ -> DB -> ルータ -> AP -> ルータ -> クライアント」の経路をAP -> DBに直接飛べるようにすると以下のようになる
      - 「クライアント -> ルータ -> AP -> DB -> AP -> クライアント」
      - P345,346の図
### アプリケーションボトルネックの解消
- **データ更新のボトルネック**
  - P346-349
  - 解決策
    - 値のキャッシュ化
    - ボトルネックの分割
- **外部問い合わせのボトルネック**
  - p349-350
  - 解決策
