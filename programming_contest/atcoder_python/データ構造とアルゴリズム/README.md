# データ構造とアルゴリズム 書籍メモ

## 第0章 メモ
### bit全探索のパターンと解説
- https://drken1215.hatenablog.com/entry/2019/12/14/171657
### ナップサック問題を色々な方法で解いている
- https://dai1741.github.io/maximum-algo-2012/docs/dynamic-programming/

<br></br>

## 第1章 アルゴリズムとは
### 線形探索
- 0番目,1番目,...のように一番基本となる探索法
### 二分探索
- n/2番目より左または右,n/4番目より左または右,...のように真ん中から二分して探索していく効率的な探索法
### 深さ優先探索
- グラフ上の探索として捉え直すと見通しがよく、解法も思い浮かびやすい
### 幅優先探索
- グラフ上の探索として捉え直すと見通しがよく、解法も思い浮かびやすい
- 最短経路問題を解く時に使われる探索方法

<br></br>

## 第2章 計算量とオーダー記法
- 計算量は最悪時間ケースを考える
### 解きたい問題の制約によってアルゴリズムを決める
- いたずらに高速なアルゴリズムを選定すればいいということではない
- O(2^N)のアルゴリズムでも制約がN<=20とかなら、そのアルゴリズムでパパッと解くべき
### データ型にも気を配る
- Pythonでlistとsetの用法を間違った例
  - `if v in S_list`: vがSに含まれているかの判定でlistを使うとO(N)
  - `if v in S_set`: setを使うとO(1)
  - このような場合はsetを使ったほうが圧倒的に高速
- listの計算量

  ![2021-01-13 15 12のイメージ](https://user-images.githubusercontent.com/53253817/104413588-ea18d380-55b1-11eb-9fda-df0f930bbae0.jpeg)

- collections.dequeの計算量
  - 双方向連結リスト

  ![2021-01-13 15 13のイメージ](https://user-images.githubusercontent.com/53253817/104413589-eb4a0080-55b1-11eb-822f-57b636dbaddd.jpeg)

- set
  - ハッシュテーブル

  ![2021-01-13 15 13のイメージ (1)](https://user-images.githubusercontent.com/53253817/104413591-ebe29700-55b1-11eb-8a98-591260161544.jpeg)

- dict
  - 辞書、ハッシュテーブル

  ![2021-01-13 15 13のイメージ (2)](https://user-images.githubusercontent.com/53253817/104413595-ed13c400-55b1-11eb-879b-71315848d017.jpeg)

- 参考文献
  - https://qiita.com/Hironsan/items/68161ee16b1c9d7b25fb

<br></br>

## 第3章 全探索
- 世の中の問題は考えられるパターンを全て列強することで解ける問題がほとんど
- 効率が悪くてもまず全探索を考えることで、問題に対する深い理解を獲得することができて、効率がいいアルゴリズムに結びつくことも多い
### 線形探索法
- 一番愚直な全探索
- 応用1: 位置を特定
  - 線形探索しつつインデックスを保存しておく
- 応用2: 最小値、最大値を特定
  - 線形探索しつつminとかmaxの変数に値を格納して更新していく
### ペアの全探索
- 線形探索法の2重ループバージョン
- 用途
  - 与えられたデータから最適なペアを探索する
  - etc
### 組み合わせの全探索
- bit全探索の解説
- 用途
  - 部分和問題
- メモ
  - 部分和問題は、累積和を使っても解ける
  - 書籍には再帰関数でも解けると書いてあった
### 問題をグラフに置き換える利点
- さまざまな問題をグラフに置き換えることで、グラフの探索問題に帰着できるから

<br></br>

## 第4章 再帰と分割統治法
- 再帰関数を使うと、複雑な問題を探索することができる
- 再帰関数は、「大きな問題を初期状態に向かって解いていくボトムアップパターン」と「小さな問題を積み重ねていくトップダウンパターンがある」
  - トップダウンは753問題のように、7,75,753のようにグラフが深くなっていくに連れて答えが出来上がっていく方法
  - ボトムアップは、分割統治法のように大きい問題を小さい問題に分割して、深いところから浅い方に向かって答えが求まっていく方法
### 再帰関数のテンプレート
- ベースケースが重要で、これがないと無限に再帰呼び出しをすることになってしまう

```python
def func(引数):
    if ベースケース:
        return ベースケースに対する値
    
    # 再帰呼び出し
    func(次の引数)
    return 答え
```

### 再帰の例1: ユークリッドの互除法
- ユークリッドの互除法とは
  - 2つの整数m,nの最大公約数GCD(m,n)を求めるアルゴリズム
- 最大公約数の性質
  - mをnで割った時のあまりをrとすると、`GCD(m,n) = GCD(n,r)`
- 例: m=51, n=15
  - 51 = 15 * 3 + 6
  - 15 = 6 * 2 + 3
  - 6 = 3 * 2 + 0
  - よって、最大公約数は3

```python
def gcd(m: int, n: int) -> int:
    if n == 0:
        return m
    return gcd(n, m % n)
```

### 再帰の例2: フィボナッチ数列
- フィボナッチ数列の定義
  - F(0) = 0
  - F(1) = 1
  - F(N) = F(N-1) + F(N-2)

```python
def fibo(n: int) -> int:
    if n == 0 or n == 1:
        return n
    return fibo(n - 1) + fibo(n - 2)
```

### メモ化再帰
- メモ化とはキャッシュの考え方
  - 同じ引数の場合はキャッシュから計算結果を返すことで計算しなくて済む
- フィボナッチ数列の再帰の例をメモ化して動的計画法へ
- 「同じ引数に対する答えをメモ化する」という手法が効果的

```python
memo = [-1] * 101 # メモ化(キャッシュ)用に、-1で初期化した配列を101個定義

def fibo(n: int) -> int:
    if n == 0 or n == 1: # ベースケース
        return n
    if memo[n] != -1: # キャッシュしてあったら、キャッシュから結果を返す
        return memo[n]
    memo[n] = fibo(n - 1) + fibo(n - 2) # メモ化しつつ再帰呼び出し
    return memo[n]

# 単純な再帰でn=30: 0.5355498790740967
# メモ化再帰でn=30: 0.0003819465637207031
# 単純な再帰でn=100: 計測不能
# メモ化再帰でn=100: 0.000637054443359375

n = int(input())
print(fibo(n))
```

### 再帰の例3: 再帰関数を用いる全探索
- 部分和問題
- 一番端の値を「選ぶか」「選ばないか」で分割していく方法
  - `a[n - 1]`を選ぶ場合は`a[0]~a[n - 2]`で`w - a[n - 1]`を作る
  - `a[n - 1]`を選ばない場合は`a[0]~a[n - 2]`で`w`を作る
- メモ化で効率化することもできる
- 自分のメモ
  - 再帰関数を使って設計する時は、「一番端の値をどうするか？」ということを考える
  - 例えば「753問題」だと、一番端の値で7を選んだ場合、5を選んだ場合、3を選んだ場合、の3つに分割できる
  - 今回の場合だと、一番端の値を「選ぶか」「選ばないか」の2つに分類できる
  - そして、再帰関数を使うことでフォーカスする「一番端の値」が左に移動して行って、全体を探索することができるという仕組み
    - このように問題を小問題に分割していく仕組みを「分割統治法」という

```python
N, W = map(int, input().split())
a = list(map(int, input().split()))

def func(n: int, w: int) -> bool:
    if n == 0:
        if w == 0:
            return True
        return False

    if func(n - 1, w - a[n - 1]):
        return True
    if func(n - 1, w):
        return True
    return False

print(func(N, W))
```

### 分割統治法
- 前述の部分和の問題を再帰で解く考え方が分割統治法

<br></br>

## 第5章 動的計画法
- 動的計画法の抽象的な説明1
  - 与えられた問題全体を一連の部分問題に上手に分解し、各部分問題に対する解をメモ化しながら、小さな部分問題からより大きな部分問題へと順に解を求めていく手法
- 動的計画法の抽象的な説明2
  - 「元の問題の最適性を考えるときに、小さな問題の最適性も要求されること」を部分構造最適性という
  - 部分構造最適性を利用して、書く部分問題の最適値を求めていく方法を動的計画法という
  - つまり、`dp[現在の状態] = dp[以前の状態] + a[i]`の場合は、`dp[以前の状態]`は最適化されている必要があるということ
- 解ける問題の幅はかなり広い
- 「一連の部分問題のへの分解の仕方」はそんなに多くない
- dpテーブルというところにメモ化していく
  - dpテーブルを特別なものと捉えないで、「すでに計算したものをキャッシュするところ」と捉えるのが重要
- 自分メモ
  - 思考順序としては、「手動で解を求める -> 以前の状態を使って現在の状態を表現できないか考えてみる(dpでのメモ化) -> 一般化する」の手順
### Frog問題
- 具体的な問題を以下のように数学的にグラフに落とし込んでから考察する

  ![https---qiita-image-store s3 amazonaws com-0-182963-18cc039f-fb2e-f895-532c-be86c3ed75fc](https://user-images.githubusercontent.com/53253817/104428202-8dc0ae80-55c7-11eb-9c9c-1fe7e7bee814.jpeg)


```python
n = int(input())
h = list(map(int, input().split()))
dp = [float("inf")] * n # 無限大で初期化
dp[0] = 0
dp[1] = abs(h[0] - h[1])

for i in range(2, n):
    dp[i] = min(dp[i - 1] + abs(h[i] - h[i - 1]), dp[i - 2] + abs(h[i] - h[i - 2]))
print(dp[-1])
```

### Frog問題を「緩和」を意識して解く
- 緩和とは？
  - あとで

```python
n = int(input())
h = list(map(int, input().split()))

dp = [float("inf")] * n # 無限大で初期化
dp[0] = 0
dp[1] = abs(h[0] - h[1])

for i in range(2, n):
    dp[i] = min(dp[i], dp[i - 1] + abs(h[i] - h[i - 1])) # 「無限大」 vs 「隣に進む」
    dp[i] = min(dp[i], dp[i - 2] + abs(h[i] - h[i - 2])) # 「隣に進む」 vs 「一個飛ばしで進む」
print(dp[-1])

```

### Frog問題を「配る遷移形式」で解く
- 今までの解き方は「貰う遷移形式」といって、「現在の状態i」に「以前の状態i-1とi-2」が遷移してくるという考え方だった
  - 確定した状態i-1,i-2を使って状態iを求める
- ここでの解き方は「配る遷移形式」といって、「現在の状態i」を「未来の状態i+1とi+2」に配るという考え方で解く
  - 確定した状態iを使って、状態i+1,i+2を求める

```python
n = int(input())
h = list(map(int, input().split()))

dp = [float("inf")] * n  # 無限大で初期化
dp[0] = 0
dp[1] = abs(h[0] - h[1])

for i in range(1, n): # インデックスのスタートが1になっていることに注意
    if i + 1 < n:
        dp[i + 1] = min(dp[i + 1], dp[i] + abs(h[i + 1] - h[i]))
    if i + 2 < n:
        dp[i + 2] = min(dp[i + 2], dp[i] + abs(h[i + 2] - h[i]))

print(dp[-1])
```

### 緩和処理の条件
- 頂点uから頂点vへと遷移する辺に関する緩和処理を成立させるためには、`dp[u]`の値が確定していることが必要
  - この前提条件をいかにして定めるかで決まる

### Frog問題を再帰関数を用いた単純な全探索で解く

```python
N = int(input())
H = list(map(int, input().split()))

def dfs(n):
    if n == 0:
        return 0
    ret = float("inf")
    ret = min(ret, dfs(n - 1) + abs(H[n] - H[n - 1]))
    if n > 1:
        ret = min(ret, dfs(n - 2) + abs(H[n] - H[n - 2]))
    return ret

print(dfs(N - 1))

```

- 自分が間違えたとこ
  - `ret = min(dfs(n - 1) + abs(H[n] - H[n - 1]), dfs(n - 2) + abs(H[n] - H[n - 2]))`のように一気にやってしまった
    - `n = 1`時に`dfs(n - 2)`がアウトインデックスしてしまうからダメ
    - グラフを書いてみればわかる
- 気づいたこと
  - 再帰関数は「現在のノード = 次のノード + 次のノードへのエッジ」で求められるので、この通りに立式すればいい
    - 今回の場合は、`dfs(5) = dfs(4) + abs(H(5) - H(4))`で求められる
  - returnは難しいことを考えずに、「現在のノードからの返り値」と考えれば簡単に書けると思う

### Frog問題をメモ化再帰を使って解く
- メモ化再帰は動的計画法を再帰関数で行うバージョンのことが以下から分かる

```python
N = int(input())
H = list(map(int, input().split()))

dp = [float("inf")] * N  # 無限大で初期化
dp[0] = 0

def dfs(n):
    if dp[n] < float("inf"):
        return dp[n]
    if n == 0:
        return dp[n]
    ret = float("inf")
    ret = min(ret, dfs(n - 1) + abs(H[n] - H[n - 1]))
    if n > 1:
        ret = min(ret, dfs(n - 2) + abs(H[n] - H[n - 2]))
    dp[n] = ret
    return dp[n]

print(dfs(N - 1))
```

- 気づいたこと
  - returnが「現在のノードからの返り値」ということを理解していれば、`dp[n] = ret`をするだけでいいことがわかる

### ナップサック問題を単純な再帰で解く
- `a[n-1]`を「選ぶ」「選ばない」で分岐していくグラフを書けばわかる

```python
N, W = map(int, input().split())
weight = list(map(int, input().split()))
value = list(map(int, input().split()))

def dfs(n, w):
    if n == 0:
        return 0
    if w - weight[n - 1] < 0:
        return dfs(n - 1, w)

    val = dfs(n - 1, w - weight[n - 1]) + value[n - 1]  # a[n - 1]を選ぶ場合
    val = max(val, dfs(n - 1, w))  # a[n - 1]を選ばない場合
    return val

print(dfs(N, W))
```

- 反省点
  - dfs内で、`n-1`とするなら、呼び出しの時に`dfs(N-1, W)`としたほうが組み立てやすかった

### ナップサック問題をDPで解く
- DPは、問題をグラフに表して再帰関数で解けるならDPでも解けるということだと思うので、この段階まできたらDPテーブルを0~Nと0~Wまでの表で紙に書いてみて、埋めるにはどうしたら良いかという思考方法で進めていければいいと思う

### いったんDPを飛ばす
- 難しい、、、

<br></br>

## 第6章 二分探索法
- 狭義では、ソート済みの配列の中から目的のものを探し出す高速な探索アルゴリズム
- 
### 配列の二分探索
- 簡単なので略
